{"cells":[{"cell_type":"markdown","metadata":{"id":"Lsd4x-JYivvt"},"source":["# Collaborative filtering approach"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":392,"status":"ok","timestamp":1718014207207,"user":{"displayName":"Francesco Romeo","userId":"04891299579663001687"},"user_tz":-120},"id":"hSvWDmNpivvy"},"outputs":[{"name":"stderr","output_type":"stream","text":["/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from surprise.model_selection import cross_validate\n","from surprise import (Dataset, Reader,\n","                      accuracy, KNNBasic,\n","                      model_selection,  SVD)\n","from datasets import load_dataset\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"QUNWyOw3ivv0"},"source":["## Loading and creation of datasets\n","\n","\n","* Downloaded the entire dataset from [Link](McAuley-LabAmazon-Reviews-2023)\n","* Used only: *rating, user_id, parent_aisin, helpful_vote e verified_purchase*\n","* Creation of the dataframe Pandas\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":696077,"status":"ok","timestamp":1718014905944,"user":{"displayName":"Francesco Romeo","userId":"04891299579663001687"},"user_tz":-120},"id":"rkPCFeylivv1"},"outputs":[],"source":["dataset_review = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_Video_Games\", trust_remote_code=True)\n","\n","temp_data = pd.DataFrame(dataset_review[\"full\"])\n","df = temp_data[['rating', 'user_id', 'parent_asin','verified_purchase', 'title', 'text']]\n","df = df.drop_duplicates()\n","df = df.dropna(subset=['user_id', 'parent_asin', 'rating'])"]},{"cell_type":"markdown","metadata":{"id":"zIBZJ2J8ivv1"},"source":["## Explorative analysis of the dataset\n","### Descriptive statistics\n","* distribution of the variables\n","* measures of central tendency ( mean, median e mode )\n","* dispersion measures ( varianza, deviazione standard e intervallo interquartile)\n","\n","### Correlation analysis\n","* linear correlation (TO-DO?)\n","\n","### Dataset filtering\n","  Filtering of the dataset is made on:\n","* verified purchase = true\n","* minimum number of reviews"]},{"cell_type":"markdown","metadata":{"id":"WaMD_JDBmizw"},"source":["### Variables distribution"]},{"cell_type":"markdown","metadata":{"id":"pWvPdZ_hm9Zy"},"source":["#### Rating distribution"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":564},"executionInfo":{"elapsed":765,"status":"ok","timestamp":1718015282099,"user":{"displayName":"Francesco Romeo","userId":"04891299579663001687"},"user_tz":-120},"id":"D57Fw4zim5tg","outputId":"a8f7d396-1f17-42f0-e6f8-e3f2d713dc8b"},"outputs":[],"source":["rating_counts = df['rating'].value_counts()\n","print(rating_counts)\n","# Creazione del grafico a barre\n","plt.figure(figsize=(10, 6))\n","plt.bar(rating_counts.index.astype(str), rating_counts.values, color='blue')\n","plt.xlabel('Ratings')\n","plt.ylabel('Number of reviews')\n","plt.title('Rating distribution (1-5)')\n","plt.xticks(range(5), labels=rating_counts.index.astype(str))\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"VqC36q_Togrk"},"source":["### Central tendency measures"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":791},"executionInfo":{"elapsed":406,"status":"ok","timestamp":1718015325685,"user":{"displayName":"Francesco Romeo","userId":"04891299579663001687"},"user_tz":-120},"id":"oNFVPpU8ouVs","outputId":"2a50cba6-8a08-45df-b165-fb619088d3fe"},"outputs":[],"source":["df.describe()"]},{"cell_type":"markdown","metadata":{"id":"at_2uBMrpLVH"},"source":["### Dispersion measures"]},{"cell_type":"markdown","metadata":{"id":"HmHjv2WdpyfG"},"source":["#### Variance and standard deviation of rating"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":449,"status":"ok","timestamp":1718023730262,"user":{"displayName":"Francesco Romeo","userId":"04891299579663001687"},"user_tz":-120},"id":"1O1dB4aQxOPd","outputId":"de320f8a-25b5-4e56-b381-69769035b20e"},"outputs":[],"source":["print(f\"Valore massimo presente: {df['rating'].max():>3}\")\n","print(f\"Valore minimo presente: {df['rating'].min():>4}\")\n","print(f\"Varianza: {round(df['rating'].var(), 3):>20}\")\n","print(f\"Deviazione standard: {round(df['rating'].std(), 3):>8}\")"]},{"cell_type":"markdown","metadata":{"id":"y0HAvi-ypaJc"},"source":["### Dataset filtering"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14270,"status":"ok","timestamp":1718024268962,"user":{"displayName":"Francesco Romeo","userId":"04891299579663001687"},"user_tz":-120},"id":"g_BoJ8D-ivv3"},"outputs":[],"source":["min_reviews_per_user = 15\n","min_reviews_per_product = 10\n","\n","df_filtring = df.drop_duplicates()\n","\n","df_filtring = df_filtring[df_filtring['verified_purchase'] == True]\n","\n","user_review_counts = df_filtring['user_id'].value_counts()\n","users_with_min_reviews = user_review_counts[user_review_counts >= min_reviews_per_user].index\n","\n","filtered_df = df[df['user_id'].isin(users_with_min_reviews)]\n","\n","item_review_counts = filtered_df.groupby('parent_asin')['user_id'].nunique()\n","products_with_min_reviews = item_review_counts[item_review_counts >= min_reviews_per_product].index\n","\n","filtered_df = filtered_df[filtered_df['parent_asin'].isin(products_with_min_reviews)]\n","filtered_df = filtered_df[filtered_df['verified_purchase'] == True]\n","num_products = filtered_df['parent_asin'].nunique()\n","num_users = filtered_df['user_id'].nunique()\n","num_reviews = len(filtered_df)\n","\n","print(f'Numero di prodotti: {num_products}')\n","print(f'Numero di utenti: {num_users}')\n","print(f'Numero di recensioni totali: {num_reviews}')\n"]},{"cell_type":"markdown","metadata":{"id":"lzqBH2UQM_K9"},"source":["## K-NN\n","\n","* Creation of the dataset with surprise\n","*   Looking for the best conf of the kNN \n","*   Study the best RMSE, MSE\n","\n","### KNN, SVD comparison\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":485,"status":"ok","timestamp":1718026149584,"user":{"displayName":"Francesco Romeo","userId":"04891299579663001687"},"user_tz":-120},"id":"Qjy27g8Kivv5"},"outputs":[],"source":["reader = Reader(rating_scale=(1, 5))\n","reviews_filtered_surprise = Dataset.load_from_df(filtered_df[['user_id', 'parent_asin', 'rating']], reader)"]},{"cell_type":"markdown","metadata":{"id":"pcAlMClOeLK7"},"source":["#### Best conf. with KNN"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23036,"status":"ok","timestamp":1718026301100,"user":{"displayName":"Francesco Romeo","userId":"04891299579663001687"},"user_tz":-120},"id":"pJvMR-Jqivv-","outputId":"47a2f5fc-2cf7-4593-d566-09753bae21d2"},"outputs":[],"source":["param_grid = {\n","    'k': list(range(15, 45, 5)),\n","    'sim_options': {\n","        'name': ['cosine', 'msd'],\n","        'user_based': [True, False],\n","    },\n","}\n","# Initialize and train the Grid Search\n","gs = model_selection.GridSearchCV(KNNBasic, param_grid,\n","                                  measures=[\"rmse\", \"mse\"],\n","                                  cv=5,\n","                                  n_jobs=-1)\n","gs.fit(reviews_filtered_surprise)\n","\n","print(f'Best RMSE = {gs.best_score[\"rmse\"]:.4f}')\n","print(f'Best configuration = {gs.best_params[\"rmse\"]}')"]},{"cell_type":"markdown","metadata":{"id":"uMhKTtiAeOQw"},"source":["#### Best conf with SVD"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21250,"status":"ok","timestamp":1718026331459,"user":{"displayName":"Francesco Romeo","userId":"04891299579663001687"},"user_tz":-120},"id":"1dDQxC05ivv-","outputId":"db7faa38-d641-43b6-d1e7-52506f6d5253"},"outputs":[],"source":["param_grid = {\n","    'n_factors': list(range(80, 160, 20)),\n","    'n_epochs': list(range(10, 50, 10)),\n","    'biased': [True, False]\n","    }\n","gs = model_selection.GridSearchCV(SVD, param_grid,\n","                                  measures=[\"rmse\", \"mse\"],\n","                                  cv=5,\n","                                  n_jobs=-1)\n","gs.fit(reviews_filtered_surprise)\n","print(f'Best RMSE = {gs.best_score[\"rmse\"]:.4f}')\n","print(f'Best configuration = {gs.best_params[\"rmse\"]}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["filtered_df"]},{"cell_type":"markdown","metadata":{"id":"aNilevZQivv_"},"source":["## Matrix filling with kNN\n","\n","*   Creation of the test and training set\n","*   Matrix filling a\n","* Reccomended items\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":463,"status":"ok","timestamp":1718026846086,"user":{"displayName":"Francesco Romeo","userId":"04891299579663001687"},"user_tz":-120},"id":"NgMbP6K2YM0z","outputId":"77b9a3b8-c956-4e6f-f77a-0ae87200d3a2"},"outputs":[],"source":["trainset = reviews_filtered_surprise.build_full_trainset()\n","algo = KNNBasic(k=40, sim_options={'name': 'cosine', 'user_based': False})\n","algo.fit(trainset)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4186,"status":"ok","timestamp":1718026854566,"user":{"displayName":"Francesco Romeo","userId":"04891299579663001687"},"user_tz":-120},"id":"iLeOVPiXivwF"},"outputs":[],"source":["users_id = filtered_df[\"user_id\"].unique()\n","items_id = filtered_df[\"parent_asin\"].unique()\n","filled_rating_matrix = []\n","for uid in users_id:\n","  filled_rating_matrix.append([])\n","  for iid in items_id:\n","    res = algo.predict(uid=uid, iid=iid)\n","    if res.r_ui is not None:\n","      filled_rating_matrix[-1].append(0)\n","    else:\n","      filled_rating_matrix[-1].append(res.est)\n","\n","filled_rating_matrix = np.array(filled_rating_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IMIw34pHivwF","outputId":"9c7a29ef-e2f0-42b0-9870-7ac85a87e702"},"outputs":[],"source":["filled_rating_matrix"]},{"cell_type":"markdown","metadata":{"id":"GGB2V7mnivwG"},"source":["\n","### Recommended list"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":447,"status":"ok","timestamp":1718026865955,"user":{"displayName":"Francesco Romeo","userId":"04891299579663001687"},"user_tz":-120},"id":"14KVLM38ivwG"},"outputs":[],"source":["res_df = pd.DataFrame(filled_rating_matrix)\n","res_df.columns = items_id\n","res_df = res_df.set_index(users_id)\n","# Sort each row by the score\n","def sort_columns(row):\n","  sorted_columns = sorted(row.items(), key=lambda x: x[1], reverse=True)\n","  return [col[0] for col in sorted_columns]\n","rec_lists = pd.DataFrame(list(res_df.apply(sort_columns, axis=1)),\n","                         index=res_df.index)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":255},"executionInfo":{"elapsed":421,"status":"ok","timestamp":1718026873498,"user":{"displayName":"Francesco Romeo","userId":"04891299579663001687"},"user_tz":-120},"id":"I9JkLx_iivwH","outputId":"bdb27078-cd27-4642-9dac-1e52c87f7944"},"outputs":[],"source":["rec_lists[:5]"]},{"cell_type":"markdown","metadata":{"id":"Ri5pflGlivwH"},"source":["## Segmentation of the user, based on cluster algo\n"]},{"cell_type":"markdown","metadata":{"id":"uNBUosWZaUFf"},"source":["#### Cluster number"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13556,"status":"ok","timestamp":1718028154756,"user":{"displayName":"Francesco Romeo","userId":"04891299579663001687"},"user_tz":-120},"id":"i4O3Hp-sivwI","outputId":"eb24a0f4-5917-43fb-ecdb-c848b5aaaf0f"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n","import numpy as np\n","\n","user_similarity = cosine_similarity(filled_rating_matrix)\n","graph = True\n","\n","max_clusters = 10\n","\n","'''\n","Elbow: punto dove smette di crescere/decrescere velocemente\n","Silhouette: più il valore è alto meglio è\n","Calinski-Harabasz: più il valore è alto meglio è\n","Davies-Bouldin: più il valore è basso meglio è\n","'''\n","\n","wcss = []\n","silhouette_scores = []\n","calinski_scores = []\n","davies_scores = []\n","\n","for i in range(2, max_clusters + 1):\n","    kmeans = KMeans(n_clusters=i, random_state=42)\n","    clusters = kmeans.fit_predict(user_similarity)\n","\n","    # WCSS (Elbow Method)\n","    wcss.append(kmeans.inertia_)\n","\n","    # Silhouette Score\n","    silhouette_scores.append(silhouette_score(user_similarity, clusters))\n","\n","    # Calinski-Harabasz Index\n","    calinski_scores.append(calinski_harabasz_score(user_similarity, clusters))\n","\n","    # Davies-Bouldin Index\n","    davies_scores.append(davies_bouldin_score(user_similarity, clusters))\n","\n","# Standardize the scores\n","wcss = np.array(wcss)\n","silhouette_scores = np.array(silhouette_scores)\n","calinski_scores = np.array(calinski_scores)\n","davies_scores = np.array(davies_scores)\n","\n","wcss_std = (wcss - wcss.mean()) / wcss.std()\n","silhouette_std = (silhouette_scores - silhouette_scores.mean()) / silhouette_scores.std()\n","calinski_std = (calinski_scores - calinski_scores.mean()) / calinski_scores.std()\n","davies_std = (davies_scores - davies_scores.mean()) / davies_scores.std()\n","\n","# Combine the standardized scores (Note: WCSS should be minimized, so we take its negative)\n","combined_scores = -wcss_std + silhouette_std + calinski_std - davies_std\n","\n","# Find the number of clusters that minimizes the combined score\n","optimal_clusters = np.argmin(combined_scores) + 2\n","\n","if graph:\n","  # Plotting the results\n","  fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n","\n","  # Elbow Method\n","  axs[0, 0].plot(range(2, max_clusters + 1), wcss, marker='o')\n","  axs[0, 0].scatter(optimal_clusters, wcss[optimal_clusters - 2], color='red', s=100, zorder=5)\n","  axs[0, 0].set_xlabel('Number of Clusters')\n","  axs[0, 0].set_ylabel('WCSS')\n","  axs[0, 0].set_title('Elbow Method')\n","\n","  # Silhouette Score\n","  axs[0, 1].plot(range(2, max_clusters + 1), silhouette_scores, marker='o')\n","  axs[0, 1].scatter(optimal_clusters, silhouette_scores[optimal_clusters - 2], color='red', s=100, zorder=5)\n","  axs[0, 1].set_xlabel('Number of Clusters')\n","  axs[0, 1].set_ylabel('Silhouette Score')\n","  axs[0, 1].set_title('Silhouette Score Method')\n","\n","  # Calinski-Harabasz Index\n","  axs[1, 0].plot(range(2, max_clusters + 1), calinski_scores, marker='o')\n","  axs[1, 0].scatter(optimal_clusters, calinski_scores[optimal_clusters - 2], color='red', s=100, zorder=5)\n","  axs[1, 0].set_xlabel('Number of Clusters')\n","  axs[1, 0].set_ylabel('Calinski-Harabasz Index')\n","  axs[1, 0].set_title('Calinski-Harabasz Index Method')\n","\n","  # Davies-Bouldin Index\n","  axs[1, 1].plot(range(2, max_clusters + 1), davies_scores, marker='o')\n","  axs[1, 1].scatter(optimal_clusters, davies_scores[optimal_clusters - 2], color='red', s=100, zorder=5)\n","  axs[1, 1].set_xlabel('Number of Clusters')\n","  axs[1, 1].set_ylabel('Davies-Bouldin Index')\n","  axs[1, 1].set_title('Davies-Bouldin Index Method')\n","\n","  plt.tight_layout()\n","  plt.show()\n","\n","print(f\"Optimal number of clusters: {optimal_clusters}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cr0kp42qdiIG"},"outputs":[],"source":["kmeans = KMeans(n_clusters=optimal_clusters)\n","\n","clusters = kmeans.fit_predict(user_similarity)\n","user_cluster_mapping = {uid: cluster for uid, cluster in zip(users_id, clusters)}"]},{"cell_type":"markdown","metadata":{"id":"4d_g3MgJivwJ"},"source":["## Top k ITEMS for USER"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def select_top_k_recommendations(rec_lists, k):\n","    top_k_recommendations = {}\n","    for user_id, row in rec_lists.iterrows():\n","        top_k_recommendations[user_id] = row[:k].tolist()\n","    return top_k_recommendations\n","\n","k = int(input('Insersici il numero di item per ogni lista: '))\n","top_k_recommendations = select_top_k_recommendations(rec_lists, k)\n","for user_id, recommendations in top_k_recommendations.items():\n","    print(\"User:\", user_id)\n","    print(\"Top\", len(recommendations), \"Recommendations:\", recommendations)\n","    print()"]},{"cell_type":"markdown","metadata":{},"source":["## Matrix filling with SVD\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["trainset = reviews_filtered_surprise.build_full_trainset()\n","algo = SVD(n_factors=80, n_epochs=20, biased=True)\n","algo.fit(trainset)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["users_id = filtered_df[\"user_id\"].unique()\n","items_id = filtered_df[\"parent_asin\"].unique()\n","filled_rating_matrix = []\n","for uid in users_id:\n","  filled_rating_matrix.append([])\n","  for iid in items_id:\n","    res = algo.predict(uid=uid, iid=iid)\n","    if res.r_ui is not None:\n","      filled_rating_matrix[-1].append(0)\n","    else:\n","      filled_rating_matrix[-1].append(res.est)\n","\n","filled_rating_matrix = np.array(filled_rating_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["filled_rating_matrix"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["res_df = pd.DataFrame(filled_rating_matrix)\n","res_df.columns = items_id\n","res_df = res_df.set_index(users_id)\n","# Sort each row by the score\n","def sort_columns(row):\n","  sorted_columns = sorted(row.items(), key=lambda x: x[1], reverse=True)\n","  return [col[0] for col in sorted_columns]\n","rec_lists = pd.DataFrame(list(res_df.apply(sort_columns, axis=1)),\n","                         index=res_df.index)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rec_lists[:5]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4265,"status":"ok","timestamp":1718028311791,"user":{"displayName":"Francesco Romeo","userId":"04891299579663001687"},"user_tz":-120},"id":"s5B3oBP5ivwJ","outputId":"58656acf-66a7-4f78-dfe4-f2e993fa14de"},"outputs":[],"source":["def select_top_k_recommendations(rec_lists, k):\n","    top_k_recommendations = {}\n","    for user_id, row in rec_lists.iterrows():\n","        top_k_recommendations[user_id] = row[:k].tolist()\n","    return top_k_recommendations\n","\n","# Esempio di utilizzo\n","k = int(input('Insersici il numero di item per ogni lista: '))\n","top_k_recommendations = select_top_k_recommendations(rec_lists, k)\n","for user_id, recommendations in top_k_recommendations.items():\n","    print(\"User:\", user_id)\n","    print(\"Top\", len(recommendations), \"Recommendations:\", recommendations)\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"4HV6WFSjivwK"},"source":["# Content Based approach"]},{"cell_type":"markdown","metadata":{"id":"Q4Y5yuK_ivwK"},"source":["### Pre-Processing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s7V_Y8XCivwK"},"outputs":[],"source":["from datasets import load_dataset\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qmCZ5q5uivwL"},"outputs":[],"source":["dataset_meta = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_meta_Video_Games\", split=\"full\", trust_remote_code=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-qLMpbH-ivwL"},"outputs":[],"source":["temp_df_meta = pd.DataFrame(dataset_meta)\n","df_meta = temp_df_meta[['title','description','parent_asin', 'rating_number']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CGedL1T1ivwM"},"outputs":[],"source":["df_meta_filtered = df_meta[df_meta['rating_number'] > 10]\n","df_meta_filtered = df_meta_filtered[df_meta_filtered['description'].apply(lambda x: len(x) >15)]\n","df_meta_filtered = df_meta_filtered.reset_index(drop=True)\n","\n","\n","\n","print(f\"Numero totale di prodotti prima dell'applicazione dei filtri: {len(df_meta):>10}\")\n","print(f\"Numero totale di prodotti dopo l'applicazione dei filtri: {len(df_meta_filtered):>11}\")\n","df_meta_filtered"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["min_reviews_per_user = 30\n","\n","df_filtring_meta = df.drop_duplicates()\n","\n","df_filtring_meta = df_filtring_meta[df_filtring_meta['verified_purchase'] == True]\n","\n","user_review_counts = df_filtring_meta['user_id'].value_counts()\n","users_with_min_reviews = user_review_counts[user_review_counts >= min_reviews_per_user].index\n","filtered_df_meta_avan = df[df['user_id'].isin(users_with_min_reviews)]\n","item_review_counts = filtered_df_meta_avan.groupby('parent_asin')['user_id'].nunique()\n","filtered_df_meta_avan = filtered_df_meta_avan[filtered_df_meta_avan['verified_purchase'] == True]\n","num_products = filtered_df_meta_avan['parent_asin'].nunique()\n","num_users = filtered_df_meta_avan['user_id'].nunique()\n","num_reviews = len(filtered_df_meta_avan)\n","\n","print(f'Numero di prodotti: {num_products}')\n","print(f'Numero di utenti: {num_users}')\n","print(f'Numero di recensioni totali: {num_reviews}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["filtered_df = filtered_df_meta_avan[filtered_df_meta_avan['parent_asin'].isin(df_meta_filtered['parent_asin'])]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["filtered_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_meta_filtered"]},{"cell_type":"markdown","metadata":{"id":"DHYaKKidivwN"},"source":["## Processing text column"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ufF9V2yivwP"},"outputs":[],"source":["import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","from nltk.stem import WordNetLemmatizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y99QZ8rJivwP","outputId":"3c4cef7d-7e4a-4ce7-9410-dec4aae81c87"},"outputs":[],"source":["nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def list_to_str(lst):\n","    return str(lst)\n","\n","df_meta_filtered['description'] = df_meta_filtered['description'].apply(list_to_str)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lemmatizer = WordNetLemmatizer() # meglio dello stemmer\n","stop_words = set(stopwords.words(\"english\"))\n","def preprocess_text(text):\n","    if isinstance(text, str):\n","        tokens = word_tokenize(text.lower())\n","        tokens = [word for word in tokens if word.isalnum()]\n","        tokens = [word for word in tokens if word not in stop_words]\n","        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n","        return ' '.join(tokens)\n","    else:\n","        return ''\n","\n","# ho tolto le colonne title e description rating_number, helpful_vote, verified_purchase e lasciato solo quelle processate\n","df_meta_filtered['text'] = (df_meta_filtered['title'] + ' ' + df_meta_filtered[\"description\"]).apply(preprocess_text)\n","df_meta_filtered.drop_duplicates()\n","df_meta_filtered.sample(1)"]},{"cell_type":"markdown","metadata":{"id":"KjC4MkMmivwR"},"source":["## Text Embedding - BoW Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","from collections import defaultdict\n","import string"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O7Q5hxtpivwS"},"outputs":[],"source":["lemmatizer = WordNetLemmatizer()\n","stop_words = set(stopwords.words(\"english\"))\n","punctuation = set(string.punctuation)\n","\n","vocab = set()\n","bow_model = []\n","raw_text = df_meta_filtered[\"text\"]\n","for text in (raw_text):\n","    word_counts = defaultdict(int)\n","    tokens = word_tokenize(text.lower())\n","    tokens = [lemmatizer.lemmatize(word) for word in tokens if word.isalnum() and word not in stop_words]\n","    \n","    vocab.update(tokens)\n","    for word in tokens:\n","        word_counts[word] += 1\n","    \n","    bow_model.append(word_counts)\n","\n","vocab = list(vocab)\n","print(f\"Numero di parole nel vocabolario: {len(vocab)}\")\n","print(f\"Le 10 parole più frequenti nel primo documento: {sorted(vocab, key=lambda x: bow_model[0].get(x, 0), reverse=True)[:10]}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ytqpQsZNivwU","outputId":"39a1c6e4-60e0-4740-9f0d-442535ad1e9a"},"outputs":[],"source":["bow_data = pd.DataFrame(0, index=range(len(raw_text)), columns=list(vocab))\n","for i in range(len(df_meta_filtered['text'])):\n","  bow_data.loc[i, bow_model[i].keys()] = bow_model[i].values()\n","bow_data\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.feature_extraction.text import CountVectorizer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["vectorizer = CountVectorizer()\n","bow_model = vectorizer.fit_transform(df_meta_filtered['text'])\n","bow_dataset = pd.DataFrame(bow_model.toarray(), columns=vectorizer.get_feature_names_out())\n","bow_dataset[\"parent_asin\"] = df_meta_filtered[\"parent_asin\"]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["bow_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["user_id = 'AHLK5V5OBWUPTZZMJ2XIKBR4LUHA'\n","print(f'User: {user_id}')\n","user_ratings = filtered_df[filtered_df['user_id'] == user_id]\n","rated_items = bow_dataset[bow_dataset['parent_asin'].isin(user_ratings['parent_asin'])]\n","print(f'# rated items: {len(rated_items)}')\n","dataset = pd.merge(rated_items, user_ratings, on=\"parent_asin\")\n","dataset = dataset.drop(columns=[\"parent_asin\", \"user_id\", \"verified_purchase\", \"title_y\", \"text_y\"])\n","dataset.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.metrics import mean_squared_error"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(dataset.drop(columns=\"rating_y\"),\n","                                                    dataset['rating_y'],\n","                                                    test_size=0.20,\n","                                                    random_state=0)\n","neigh_reg = KNeighborsRegressor(n_neighbors=10, metric=\"cosine\")\n","neigh_reg.fit(X_train, y_train)\n","y_pred = neigh_reg.predict(X_test)\n","mse = mean_squared_error(y_test, y_pred)\n","rmse = np.sqrt(mse)\n","print(f'MSE = {mse:.6f}')\n","print(f'RMSE = {rmse:.6f}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["mse_users = []\n","for user_id in filtered_df[\"user_id\"].unique():\n","  user_ratings = filtered_df[filtered_df['user_id'] == user_id]\n","  rated_items = bow_dataset[bow_dataset['parent_asin'].isin(user_ratings['parent_asin'])]\n","  dataset = pd.merge(rated_items, user_ratings, on=\"parent_asin\")\n","  dataset = dataset.drop(columns=[\"parent_asin\", \"user_id\", \"verified_purchase\", \"title_y\", \"text_y\"])\n","  try:\n","    X_train, X_test, y_train, y_test = train_test_split(dataset.drop(columns=\"rating_y\"),\n","                                                        dataset['rating_y'],\n","                                                        test_size=0.20,\n","                                                        random_state=0)\n","    neigh_reg = KNeighborsRegressor(n_neighbors=min(20, len(X_train)),\n","                                    metric=\"cosine\")\n","    neigh_reg.fit(X_train, y_train)\n","    y_pred = neigh_reg.predict(X_test)\n","    mse = mean_squared_error(y_test, y_pred)\n","    mse_users.append(mse)\n","  except:\n","    continue"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(f\"Average MSE over users: {np.mean(mse_users):.2f}\")\n","print(f\"Average RMSE over users: {np.sqrt(np.mean(mse_users)):.2f}\")"]},{"cell_type":"markdown","metadata":{"id":"9P5ia8MuivwZ"},"source":["## Text Embedding - Transformers Models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"88HSPV-3ivwa"},"outputs":[],"source":["import numpy as np\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.metrics import mean_squared_error\n","from sentence_transformers import SentenceTransformer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2vro3GACivwa"},"outputs":[],"source":["model = SentenceTransformer('sentence-transformers/average_word_embeddings_komninos')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"af8APIfUivwb"},"outputs":[],"source":["embeddings = model.encode(df_meta_filtered[\"text\"])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_meta_filtered"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["embeddings_dataset = pd.DataFrame(embeddings)\n","embeddings_dataset[\"parent_asin\"] = df_meta_filtered[\"parent_asin\"]\n","embeddings_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["mse_users = []\n","for user_id in filtered_df[\"user_id\"].unique():\n","    user_ratings = filtered_df[filtered_df['user_id'] == user_id]\n","    rated_items = embeddings_dataset[embeddings_dataset['parent_asin'].isin(user_ratings['parent_asin'])]\n","    dataset_rec = pd.merge(rated_items, user_ratings, on=\"parent_asin\")\n","    dataset_rec = dataset_rec.drop(columns=[\"parent_asin\", \"user_id\"])\n","    dataset_rec = pd.get_dummies(dataset_rec, columns=dataset_rec.select_dtypes(include=['object']).columns)\n","    dataset_rec = dataset_rec.dropna()\n","    dataset_rec.columns = dataset_rec.columns.astype(str)\n","    if len(dataset_rec) == 0 or 'rating' not in dataset_rec.columns:\n","        continue\n","    try:\n","        X_train, X_test, y_train, y_test = train_test_split(dataset_rec.drop(columns=\"rating\"),\n","                                                            dataset_rec['rating'],\n","                                                            test_size=0.20,\n","                                                            random_state=0)\n","        if len(X_train) < 2:\n","            continue\n","        neigh_reg = KNeighborsRegressor(n_neighbors=min(40, len(X_train)), metric=\"cosine\")\n","        neigh_reg.fit(X_train, y_train)\n","        y_pred = neigh_reg.predict(X_test)\n","        mse = mean_squared_error(y_test, y_pred)\n","        mse_users.append(mse)\n","    except Exception as e:\n","        print(f'Error for user {user_id}: {e}')\n","        continue\n","\n","if mse_users:\n","    average_mse = np.mean(mse_users)\n","    print(f'Average MSE: {average_mse:.6f}')\n","else:\n","    print('No MSE values calculated.')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(f\"Average MSE over users: {np.mean(mse_users):.2f}\")\n","print(f\"Average RMSE over users: {np.sqrt(np.mean(mse_users)):.2f}\")"]},{"cell_type":"markdown","metadata":{},"source":["# Sentiment Analysis"]},{"cell_type":"markdown","metadata":{},"source":["## NLP "]},{"cell_type":"markdown","metadata":{},"source":["### Merge DF "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["min_reviews_per_user = 15\n","\n","df_filtring = df.drop_duplicates()\n","\n","df_filtring = df_filtring[df_filtring['verified_purchase'] == True]\n","\n","user_review_counts = df_filtring['user_id'].value_counts()\n","users_with_min_reviews = user_review_counts[user_review_counts >= min_reviews_per_user].index\n","\n","filtered_df_avan = df[df['user_id'].isin(users_with_min_reviews)]\n","\n","item_review_counts = filtered_df_avan.groupby('parent_asin')['user_id'].nunique()\n","products_with_min_reviews = item_review_counts[item_review_counts >= min_reviews_per_product].index\n","\n","filtered_df_avan = filtered_df_avan[filtered_df_avan['parent_asin'].isin(products_with_min_reviews)]\n","filtered_df_avan = filtered_df_avan[filtered_df_avan['verified_purchase'] == True]\n","num_products = filtered_df_avan['parent_asin'].nunique()\n","num_users = filtered_df_avan['user_id'].nunique()\n","num_reviews = len(filtered_df_avan)\n","\n","print(f'Numero di prodotti: {num_products}')\n","print(f'Numero di utenti: {num_users}')\n","print(f'Numero di recensioni totali: {num_reviews}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","merged_df = pd.merge(df_meta, filtered_df_avan, on='parent_asin')\n","def list_to_str(lst):\n","    return str(lst)\n","merged_df['description'] = merged_df['description'].apply(list_to_str)\n","merged_df\n"]},{"cell_type":"markdown","metadata":{},"source":["### Tokenizing "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","from nltk.stem import WordNetLemmatizer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lemmatizer = WordNetLemmatizer() # meglio dello stemmer\n","stop_words = set(stopwords.words(\"english\"))\n","def preprocess_text(text):\n","    if isinstance(text, str):\n","        tokens = word_tokenize(text.lower())\n","        tokens = [word for word in tokens if word.isalnum()]\n","        tokens = [word for word in tokens if word not in stop_words]\n","        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n","        return ' '.join(tokens)\n","    else:\n","        return ''\n","# ho tolto le colonne title e description rating_number, helpful_vote, verified_purchase e lasciato solo quelle processate\n","merged_df['title_processed'] = merged_df['title_y'].apply(preprocess_text)\n","merged_df['text_processed'] = merged_df['text'].apply(preprocess_text)\n","merged_df.drop_duplicates()\n","merged_df.head\n"]},{"cell_type":"markdown","metadata":{},"source":["### Label application"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def sentiment_label(rating):\n","    if rating <= 2:\n","        return 0\n","    elif rating == 3:\n","        return 1\n","    else:\n","        return 2\n","merged_df['sentiment'] = merged_df['rating'].apply(sentiment_label)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["merged_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["merged_df = merged_df.drop(columns=[ 'title_x','title_y','description','rating_number', 'rating' ,'user_id', 'verified_purchase' ,'text'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["merged_df = merged_df.sample(frac=0.6, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["merged_df[\"text\"] = merged_df[\"title_processed\"] + \" \" + merged_df[\"text_processed\"]\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["merged_df = merged_df.drop(columns=['title_processed' , 'text_processed'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["merged_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","neutral_count = len(merged_df[merged_df['sentiment'] == 1])\n","negative_count = len(merged_df[merged_df['sentiment'] == 0])\n","min_count = min(neutral_count, negative_count)\n","positive_sample = merged_df[merged_df['sentiment'] == 2].sample(neutral_count + negative_count, random_state=42)\n","neutral_sample = merged_df[merged_df['sentiment'] == 1].sample(min_count, random_state=42)\n","negative_sample = merged_df[merged_df['sentiment'] == 0].sample(min_count, random_state=42)\n","balanced_df = pd.concat([positive_sample, neutral_sample, negative_sample])\n","merged_df = balanced_df.dropna()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["merged_df"]},{"cell_type":"markdown","metadata":{},"source":["## EMBEDDING WITH BoW"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.metrics import mean_squared_error"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["merged_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.linear_model import LogisticRegression  # Ad esempio, puoi scegliere un modello di classificazione\n","from sklearn.metrics import classification_report, accuracy_score\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Vettorizza il testo usando CountVectorizer\n","vectorizer = CountVectorizer()\n","bow_model = vectorizer.fit_transform(merged_df[\"text\"])\n","bow_dataset = pd.DataFrame(bow_model.toarray(), columns=vectorizer.get_feature_names_out())\n","bow_dataset[\"parent_asin\"] = merged_df[\"parent_asin\"].values\n","bow_dataset[\"sentiment\"] = merged_df[\"sentiment\"].values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["bow_dataset[\"sentiment\"]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["merged_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X = bow_dataset.drop(columns=[\"parent_asin\", \"sentiment\"])  # Features\n","y = bow_dataset[\"sentiment\"]  # Target\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","model = LogisticRegression(max_iter=2000)  # Esempio di modello di regressione logistica\n","model.fit(X_train, y_train)\n","y_pred = model.predict(X_test)\n","\n","# Valutazione del modello\n","print(classification_report(y_test, y_pred))\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import classification_report\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsClassifier\n","X_train, X_test, y_train, y_test = train_test_split(bow_dataset.drop(columns=[\"parent_asin\", \"sentiment\"]),\n","                                                    bow_dataset[\"sentiment\"],\n","                                                    test_size=0.3,\n","                                                    random_state=42)\n","neigh = KNeighborsClassifier(n_neighbors=30)\n","neigh.fit(X_train, y_train)\n","y_pred = neigh.predict(X_test)\n","print(classification_report(y_test, y_pred))\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["bow_dataset"]},{"cell_type":"markdown","metadata":{},"source":["## EMBEDDING WITH TRASFOMERS"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","from transformers import AutoTokenizer, AutoModel"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def mean_pooling(model_output, attention_mask):\n","    token_embeddings = model_output[0]\n","    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n","    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["input_texts = \"classification: \" + merged_df[\"text\"]\n","input_texts = input_texts.tolist()\n","input_texts[:5]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","model = AutoModel.from_pretrained('nomic-ai/nomic-embed-text-v1.5', trust_remote_code=True, safe_serialization=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["batch_dict = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n","print(\"input_ids:\", batch_dict[\"input_ids\"].shape)\n","print(\"attention_mask:\", batch_dict[\"attention_mask\"].shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["merged_df = merged_df.sample(frac=0.05)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["batch_size = 100\n","n_instance = batch_dict[\"input_ids\"].shape[0]\n","n_batch = n_instance // batch_size + 1\n","\n","embeddings = torch.empty((0, 768))\n","for i in range(n_batch):\n","  start = i * batch_size\n","  end = (i + 1) * batch_size\n","  print(f\"{start} -> {end}\")\n","  with torch.no_grad():\n","      model_output = model(input_ids=batch_dict[\"input_ids\"][start:end],\n","                           token_type_ids=batch_dict[\"token_type_ids\"][start:end],\n","                           attention_mask=batch_dict[\"attention_mask\"][start:end])\n","  output_pooled = mean_pooling(model_output, batch_dict['attention_mask'][start:end])\n","  embeddings = torch.cat([embeddings, output_pooled])"]},{"cell_type":"markdown","metadata":{},"source":["## SENTIMENT PREDICTION"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import classification_report\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsClassifier\n","X_train, X_test, y_train, y_test = train_test_split(embeddings,\n","                                                    merged_df[\"sentiment\"],\n","                                                    test_size=0.2,\n","                                                    random_state=42)\n","neigh = KNeighborsClassifier(n_neighbors=3)\n","neigh.fit(X_train, y_train)\n","\n","y_pred = neigh.predict(X_test)\n","print(classification_report(y_test, y_pred))\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))"]}],"metadata":{"colab":{"collapsed_sections":["zIBZJ2J8ivv1","WaMD_JDBmizw","xSVz9hxgmsEd","pWvPdZ_hm9Zy","VqC36q_Togrk","nIEMubZ9p5fe","HmHjv2WdpyfG","iG3U7qoRN_DV","lzqBH2UQM_K9","TBrTQ2M6ivv4","pcAlMClOeLK7","uMhKTtiAeOQw","aNilevZQivv_","Ri5pflGlivwH","uNBUosWZaUFf","3o6TFizgdbyN","4d_g3MgJivwJ","4HV6WFSjivwK"],"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
